# Linear Regression

**Linear regression** is a simple yet powerful algorithm used for predicting continuous values. It models the relationship between the independent variables (features) and the dependent variable (target) by fitting a straight line to the data.

In linear regression, the goal is to find the best-fitting line that minimizes the difference between the predicted values and the actual values. This is typically done by minimizing the sum of the squared differences between the observed and predicted values, a method known as ordinary least squares (OLS).

The equation for a simple linear regression with one independent variable is:

$\ y = mx + b \$

Where:
- $\( y \)$ is the dependent variable (target)
- $\( x \)$ is the independent variable (feature)
- $\( m \)$ is the slope of the line
- $\( b \)$ is the y-intercept

The coefficients $\( m \)$ and $\( b \)$ are estimated from the training data, and once the model is trained, it can be used to make predictions on new data.

Linear regression is widely used in various fields, including economics, finance, healthcare, and social sciences. It's often used for tasks such as predicting sales revenue, housing prices, stock prices, and more. Despite its simplicity, linear regression can provide valuable insights and serve as a baseline model for more complex algorithms.
